# MLP

Implementation of a _Multi-Layer Perceptron_ with one variable-neuron hidden layer. Stochastic Gradient Descent (SGD) is used in training.

## References

[1] - [The Backpropagation Algorithm for Training Neural Networks](https://www.youtube.com/watch?v=IMZfiFItrLI)<br>
